{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pymongo\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\tonju\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars news URL of page to be scraped\n",
    "news_url = 'https://redplanetscience.com/'\n",
    "\n",
    "browser.visit(news_url)\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "news_soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4feb80e814f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Retrieve the latest news title and paragraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Apply inspect to identify class for news and title and save them to a variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'content_title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mparagraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews_soup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'article_teaser_body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Retrieve the latest news title and paragraph\n",
    "# Apply inspect to identify class for news and title and save them to a variable\n",
    "title = news_soup.find_all('div', class_='content_title')[0].text\n",
    "paragraph = news_soup.find_all('div', class_='article_teaser_body')[0].text\n",
    "\n",
    "print(title)\n",
    "print(\"--------------------------------------------------------------------\")\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Image to be scraped\n",
    "jpl_url = 'https://spaceimages-mars.com/'\n",
    "image_url = 'https://spaceimages-mars.com/?search=&category=Mars'\n",
    "\n",
    "browser.visit(image_url)\n",
    "\n",
    "html = browser.html\n",
    "\n",
    "images_soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve featured image link\n",
    "image_path = images_soup.find_all('img')[3][\"src\"]\n",
    "featured_image_url = jpl_url + image_path\n",
    "featured_image_url = featured_image_url.replace(\" \", \"%20\")\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_url = 'https://galaxyfacts-mars.com'\n",
    "tables = pd.read_html(facts_url)\n",
    "tables   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = tables.drop(['Earth'], axis=1)\n",
    "# tables.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_df = tables[0]\n",
    "mars_facts_df.columns = [\"Description\", \"Mars facts\", 'Earth facts']\n",
    "# mars_facts_df = mars_facts(\"Mars - Earth Comparison\", \"Mars\")\n",
    "mars_facts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_html_table = mars_facts_df.to_html()\n",
    "mars_html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_html_table.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mars_html_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://marshemispheres.com/'\n",
    "soup=BeautifulSoup(requests.get(url).text)\n",
    "links=soup.find_all('a')\n",
    "urls=[x['href'] for x in links]\n",
    "\n",
    "for x in urls:\n",
    "    print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usgs_url = 'https://astrogeology.usgs.gov'\n",
    "hemispheres_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "browser.visit(hemispheres_url)\n",
    "\n",
    "hemispheres_html = browser.html\n",
    "\n",
    "hemispheres_soup = BeautifulSoup(hemispheres_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mars_hemispheres = hemispheres_soup.find('div', class_='collapsible results')\n",
    "mars_hemispheres = all_mars_hemispheres.find_all('div', class_='item')\n",
    "\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# Iterate through each hemisphere data\n",
    "for i in mars_hemispheres:\n",
    "    # Collect Title\n",
    "    hemisphere = i.find('div', class_=\"description\")\n",
    "    title = hemisphere.h3.text\n",
    "    \n",
    "    # Collect image link by browsing to hemisphere page\n",
    "    hemisphere_link = hemisphere.a[\"href\"]    \n",
    "    browser.visit(usgs_url + hemisphere_link)\n",
    "    \n",
    "    image_html = browser.html\n",
    "    image_soup = BeautifulSoup(image_html, 'html.parser')\n",
    "    \n",
    "    image_link = image_soup.find('div', class_='downloads')\n",
    "    image_url = image_link.find('li').a['href']\n",
    "\n",
    "    # Create Dictionary to store title and url info\n",
    "    image_dict = {}\n",
    "    image_dict['title'] = title\n",
    "    image_dict['img_url'] = image_url\n",
    "    \n",
    "    hemisphere_image_urls.append(image_dict)\n",
    "\n",
    "print(hemisphere_image_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_dict = {\n",
    "        \"news_title\": title,\n",
    "        \"paragraph\": paragraph,\n",
    "        \"featured_image_url\": featured_image_url,\n",
    "        \"fact_table\": str(mars_html_table),\n",
    "        \"hemisphere_images\": hemisphere_image_urls\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
